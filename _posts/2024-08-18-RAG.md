---
layout: post
title: RAG
author: [Richard Kuo]
category: [Lecture]
tags: [jekyll, ai]
---

Introduction to RAG, LlamaIndex, examples.

---
## RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ)
**blog:** [RAG æª¢ç´¢å¢å¼·ç”Ÿæˆâ€” è®“å¤§å‹èªè¨€æ¨¡å‹æ›´è°æ˜çš„ç§˜å¯†æ­¦å™¨](https://blog.infuseai.io/rag-retrieval-augmented-generation-introduction-a5854cb6393e)<br>
![](https://blogs.mathworks.com/deep-learning/files/2024/01/rag.png)

---
### Retrieval-Augmented Generation
**Paper:** [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
![](https://eugeneyan.com/assets/rag.jpg)

---
#### [A Guide on 12 Tuning Strategies for Production-Ready RAG Applications](https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439#156e)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*tT14GpYfEMSqCjnt2UQOGQ.png)

---
#### [NLP â€¢ Retrieval Augmented Generation](https://aman.ai/primers/ai/RAG/)
<p><img width="50%" height="50%" src="https://aman.ai/primers/ai/assets/RAG/4.png"></p>

---
### [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)
<p><img width="50%" height="50%" src="https://eugeneyan.com/assets/llm-patterns-og.png"></p>

---
#### [Fusion-in-Decoder (FiD)](https://arxiv.org/abs/2007.01282)
![](https://eugeneyan.com/assets/fid.jpg)

---
#### [Retrieval-Enhanced Transformer (RETRO)](https://arxiv.org/abs/2112.04426)
![](https://eugeneyan.com/assets/retro.jpg)

---
#### [Internet-augmented LMs](https://arxiv.org/abs/2203.05115)
![](https://eugeneyan.com/assets/internet-llm.jpg)

---
#### [Overview of RAG for CodeT5+](https://arxiv.org/abs/2305.07922)
![](https://eugeneyan.com/assets/codet5.jpg)

---
#### [Hypothetical document embeddings (HyDE)](https://arxiv.org/abs/2212.10496)
![](https://eugeneyan.com/assets/hyde.jpg)

---
### LLM Embedder
**Paper:** [Retrieve Anything To Augment Large Language Models](https://arxiv.org/abs/2310.07554)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-flagembedding](https://www.kaggle.com/code/rkuo2000/llm-flagembedding)<br>
![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a4e4265-7dab-4c5d-b14f-5dfd1b270e75_746x735.png)
![](https://github.com/FlagOpen/FlagEmbedding/raw/master/FlagEmbedding/llm_embedder/imgs/llm-embedder.png)

---
### LM-Cocktail
**Paper:** [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://arxiv.org/abs/2311.13534)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail)<br>

---
### EAGLE-LLM
3X faster for LLM<br>
**Blog:** [EAGLE: Lossless Acceleration of LLM Decoding by Feature Extrapolation](https://sites.google.com/view/eagle-llm)<br>
**Code:** [https://github.com/SafeAILab/EAGLE](https://github.com/SafeAILab/EAGLE)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/eagle-llm](https://www.kaggle.com/code/rkuo2000/eagle-llm)<br>

---
### Purple Llama CyberSecEval
**Paper:** [Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models](https://arxiv.org/abs/2312.04724)<br>
**Code:** [CybersecurityBenchmarks](https://github.com/facebookresearch/PurpleLlama/tree/main/CybersecurityBenchmarks)<br>
[meta-llama/LlamaGuard-7b](https://huggingface.co/meta-llama/LlamaGuard-7b)<br>
<table>
<tr><th>           </th><th>Our Test Set (Prompt)</th><th>OpenAI Mod</th><th>ToxicChat</th><th>Our Test Set (Response)</th></tr>
<tr><td>Llama-Guard</td><td>0.945</td><td>0.847</td><td>0.626</td><td>0.953</td></tr>
<tr><td>OpenAI API</td><td>	0.764</td><td>0.856</td><td>0.588</td><td>0.769</td></tr>
<tr><td>Perspective API</td><td>0.728</td><td>0.787</td><td>0.532</td><td>0.699</td></tr>
</table>

---
## GraphRAG
**Blog:** [å¾ RAG åˆ° GraphRAGï¼šé€éåœ–è­œç¯€é»é—œä¿‚å¢å¼·å›æ‡‰ç²¾ç¢ºåº¦](https://idataagent.com/2024/05/06/from-rag-to-graphrag-enhance-response-accuracy-through-graph-node-relationships/)<br>
![](https://miro.medium.com/v2/resize:fit:786/format:webp/0*22VVg9YOaqHLRJ0-)

**Blog:** [GraphRAG: Unlocking LLM discovery on narrative private data)](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)<br>

**Paper:** [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/pdf/2404.16130)<br>
**Code:** <br>
* [GraphRAG Accelerator](https://github.com/Azure-Samples/graphrag-accelerator)
* [GraphRAG Library](https://github.com/microsoft/graphrag)

---
### HippoRAG
**Paper:** [HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831)<br>
**Code:** [https://github.com/OSU-NLP-Group/HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG)<br>
![](https://github.com/OSU-NLP-Group/HippoRAG/raw/main/images/hook_figure.png)

---
## Frameworks

### [LlamaIndex](https://www.llamaindex.ai/)
**Code:** [https://github.com/run-llama/llama_index](https://github.com/run-llama/llama_index)<br>
**Docs:** [](https://docs.llamaindex.ai/en/stable/)<br>
![](https://docs.llamaindex.ai/en/stable/_static/getting_started/basic_rag.png)
```
import os

os.environ["REPLICATE_API_TOKEN"] = "YOUR_REPLICATE_API_TOKEN"

from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.replicate import Replicate
from transformers import AutoTokenizer

# set the LLM
llama2_7b_chat = "meta/llama-2-7b-chat:8e6975e5ed6174911a6ff3d60540dfd4844201974602551e10e9e87ab143d81e"
Settings.llm = Replicate(
    model=llama2_7b_chat,
    temperature=0.01,
    additional_kwargs={"top_p": 1, "max_new_tokens": 300},
)

# set tokenizer to match LLM
Settings.tokenizer = AutoTokenizer.from_pretrained(
    "NousResearch/Llama-2-7b-chat-hf"
)

# set the embed model
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-en-v1.5"
)

documents = SimpleDirectoryReader("YOUR_DATA_DIRECTORY").load_data()
index = VectorStoreIndex.from_documents(
    documents,
)
```
```
query_engine = index.as_query_engine()
query_engine.query("YOUR_QUESTION")
```
By default, data is stored in-memory. To persist to disk (under ./storage):<br>
```
index.storage_context.persist()
```

**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-llamaindex](https://www.kaggle.com/code/rkuo2000/llm-llamaindex)

---
## Applications

### [RAG using LlamaIndex framework to build a simple chatbot, to Q&A a bunch of documents](https://abvijaykumar.medium.com/prompt-engineering-retrieval-augmented-generation-rag-cd63cdc6b00)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*PL-HZqYOdczK4PoZjEPlKQ.png)

---
### [RAG with MATLAB](https://blogs.mathworks.com/deep-learning/2024/01/22/large-language-models-with-matlab/)
![](https://blogs.mathworks.com/deep-learning/files/2024/01/LLMs_recording.gif)

---
### [Building RAG-based LLM Applications for Production](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)
**[https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb](https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb)**<br>
(1)å°‡å¤–éƒ¨æ–‡ä»¶åšåˆ†å¡Š(chunking)å†åˆ†è©(tokenize)è½‰æˆtoken<br>
(2)åˆ©ç”¨åµŒå…¥æ¨¡å‹ï¼Œå°‡tokenåšåµŒå…¥(embeds)é‹ç®—ï¼Œè½‰æˆå‘é‡ï¼Œå„²å­˜è‡³å‘é‡è³‡æ–™åº«(Vector Database)ä¸¦ç´¢å¼•(Indexes)<br>
(3)ç”¨æˆ¶æå‡ºå•é¡Œï¼Œå‘é‡è³‡æ–™åº«å°‡å•é¡Œå­—ä¸²è½‰æˆå‘é‡(åˆ©ç”¨å‰ä¸€å€‹æ­¥é©Ÿçš„åµŒå…¥æ¨¡å‹)ï¼Œå†é€éé¤˜å¼¦(Cosine)ç›¸ä¼¼åº¦æˆ–æ­æ°è·é›¢æ¼”ç®—æ³•ä¾†æœå°‹è³‡æ–™åº«è£¡çš„è¿‘ä¼¼è³‡æ–™<br>
(4)å°‡ç”¨æˆ¶çš„å•é¡Œã€è³‡æ–™åº«æŸ¥è©¢çµæœä¸€èµ·æ”¾é€²Prompt(æç¤º)ï¼Œäº¤ç”±LLMæ¨ç†å‡ºæœ€çµ‚ç­”æ¡ˆ<br>
ä»¥ä¸Šæ˜¯åŸºæœ¬çš„RAGæµç¨‹ï¼Œåˆ©ç”¨Langchainæˆ–LlamaIndexæˆ–Haystackä¹‹é¡çš„æ‡‰ç”¨ç¨‹å¼é–‹ç™¼æ¡†æ¶ï¼Œå¤§æ¦‚ç”¨ä¸åˆ°ä¸€ç™¾è¡Œçš„ç¨‹å¼ç¢¼å°±èƒ½åšæ‰(å«LLMçš„è£è¼‰)ã€‚<br>

Anyscaleå‰›å‰›ç™¼å¸ƒçš„ä¸€ç¯‡ç²¾å½©å¥½æ–‡ï¼Œè£¡é ­ä»‹ç´¹äº†å¾ˆå¤šæå‡RAGæˆæ•ˆçš„é«˜æ®µæŠ€å·§ï¼Œå…§å®¹åŒ…æ‹¬ï¼š<br>
ğŸš€å¾é ­é–‹å§‹å»ºæ§‹åŸºæ–¼RAGçš„LLMæ‡‰ç”¨ç¨‹å¼ã€‚<br>
ğŸš€ åœ¨å…·æœ‰ä¸åŒé‹ç®—è³‡æºçš„å¤šå€‹å·¥ä½œäººå“¡ä¹‹é–“æ“´å±•ä¸»è¦å·¥ä½œè² è¼‰ï¼ˆè¼‰å…¥ã€åˆ†å¡Šã€åµŒå…¥ã€ç´¢å¼•ã€æœå‹™ç­‰ï¼‰ã€‚<br>
ğŸš€è©•ä¼°æ‡‰ç”¨ç¨‹å¼çš„ä¸åŒé…ç½®ï¼Œä»¥æœ€ä½³åŒ–æ¯å€‹å…ƒä»¶ï¼ˆä¾‹å¦‚retrieval_scoreï¼‰å’Œæ•´é«”æ•ˆèƒ½ï¼ˆquality_scoreï¼‰ã€‚<br>
ğŸš€ é€éé–‹æºå’Œé–‰æºLLMå¯¦ä½œæ··åˆä»£ç†è·¯ç”±æ–¹æ³•ï¼Œä»¥å»ºç«‹æ•ˆèƒ½æœ€ä½³ä¸”æœ€å…·æˆæœ¬æ•ˆç›Šçš„æ‡‰ç”¨ç¨‹å¼ã€‚<br>
ğŸš€ä»¥é«˜æ“´å±•æ€§èˆ‡é«˜å¯ç”¨æ€§çš„æ–¹å¼ç‚ºæ‡‰ç”¨ç¨‹å¼æä¾›æœå‹™ã€‚<br>
ğŸš€äº†è§£å¾®èª¿ã€æç¤ºå·¥ç¨‹ã€è©å½™æœå°‹(lexical search)ã€é‡æ–°æ’åã€è³‡æ–™é£›è¼ª(data flywheel)ç­‰æ–¹æ³•å¦‚ä½•å½±éŸ¿æ‡‰ç”¨ç¨‹å¼çš„æ•ˆèƒ½ã€‚<br>

---
### TAG (Table-Augmented Generation)
**Blog:** [Goodbye, Text2SQL: Why Table-Augmented Generation (TAG) is the Future of AI-Driven Data Queries!](https://ai.plainenglish.io/goodbye-text2sql-why-table-augmented-generation-tag-is-the-future-of-ai-driven-data-queries-892e24e06922)<br>
**Code:** [https://github.com/TAG-Research/TAG-Bench](https://github.com/TAG-Research/TAG-Bench)<br>
![](https://github.com/TAG-Research/TAG-Bench/raw/main/assets/tag.png)

<br>
<br>

*This site was last updated {{ site.time | date: "%B %d, %Y" }}.*

